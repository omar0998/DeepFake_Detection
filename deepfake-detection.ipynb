{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":939937,"sourceType":"datasetVersion","datasetId":501529}],"dockerImageVersionId":30685,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction to Deepfake Detection\nDeepfakes are synthetic media (usually videos or images) created using deep learning techniques. They convincingly replace a person’s likeness in existing media with someone else’s, often leading to misinformation and potential harm. Detecting deepfakes is crucial for maintaining trust in visual content.","metadata":{}},{"cell_type":"markdown","source":"**on this project we will use dataset** ***140k Real and Fake Faces***\n\nThis dataset consists of all 70k REAL faces from the Flickr dataset collected by Nvidia, as well as 70k fake faces sampled from the 1 Million FAKE faces (generated by StyleGAN) that was provided by Bojan.\n\nIn this dataset, I convenient combined both dataset, resized all the images into 256px, and split the data into train, validation and test set. I also included some CSV files for convenience.","metadata":{}},{"cell_type":"code","source":"import os\nimport tensorflow as tf\nimport keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications.vgg16 import preprocess_input\nfrom tensorflow.keras.applications import Xception\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras import Model\n","metadata":{"id":"i3fcbLPvNkeI","execution":{"iopub.status.busy":"2024-05-02T22:52:28.489864Z","iopub.execute_input":"2024-05-02T22:52:28.490136Z","iopub.status.idle":"2024-05-02T22:52:43.306412Z","shell.execute_reply.started":"2024-05-02T22:52:28.490108Z","shell.execute_reply":"2024-05-02T22:52:43.305469Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/140k-real-and-fake-faces/train.csv\")\ntest_data  = pd.read_csv(\"/kaggle/input/140k-real-and-fake-faces/test.csv\")\nvalidation_data = pd.read_csv(\"/kaggle/input/140k-real-and-fake-faces/valid.csv\")","metadata":{"id":"yKE-nzDaNwWA","execution":{"iopub.status.busy":"2024-05-02T22:02:06.126440Z","iopub.execute_input":"2024-05-02T22:02:06.127183Z","iopub.status.idle":"2024-05-02T22:02:06.813597Z","shell.execute_reply.started":"2024-05-02T22:02:06.127141Z","shell.execute_reply":"2024-05-02T22:02:06.812539Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path=\"/kaggle/input/140k-real-and-fake-faces/real_vs_fake/real-vs-fake\"","metadata":{"id":"baKXsMXlNw4t","execution":{"iopub.status.busy":"2024-05-02T22:02:06.935770Z","iopub.execute_input":"2024-05-02T22:02:06.936162Z","iopub.status.idle":"2024-05-02T22:02:06.940809Z","shell.execute_reply.started":"2024-05-02T22:02:06.936125Z","shell.execute_reply":"2024-05-02T22:02:06.939785Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Preprocessing and Augmentation\nThe ImageDataGenerator is a powerful tool for data augmentation and preprocessing in deep learning. It generates batches of augmented image data on-the-fly during training.","metadata":{}},{"cell_type":"code","source":"train_image_generator = ImageDataGenerator(rescale=1./255.,preprocessing_function=preprocess_input)\n\ntrain_data_generator = train_image_generator.flow_from_dataframe(\n    dataframe=train_data,\n    directory=path,\n    x_col ='path',\n    y_col ='label_str',\n    color_mode=\"rgb\",\n    target_size=(256, 256),\n    class_mode=\"binary\",\n    batch_size=32,\n    shuffle = True\n)\n","metadata":{"id":"bVqY_NIVNyBG","execution":{"iopub.status.busy":"2024-05-02T22:02:08.254549Z","iopub.execute_input":"2024-05-02T22:02:08.255649Z","iopub.status.idle":"2024-05-02T22:05:43.174477Z","shell.execute_reply.started":"2024-05-02T22:02:08.255605Z","shell.execute_reply":"2024-05-02T22:05:43.173376Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"validation_image_generator = ImageDataGenerator(rescale=1./255.,preprocessing_function=preprocess_input)\ntest_image_generator = ImageDataGenerator(rescale=1./255.,preprocessing_function=preprocess_input)\n\nvalidation_data_generator = validation_image_generator.flow_from_dataframe(\n    dataframe=validation_data,\n    directory=path,\n    x_col ='path',\n    y_col ='label_str',\n    color_mode=\"rgb\",\n    target_size=(256, 256),\n    class_mode=\"binary\",\n    batch_size=32,\n    shuffle = True\n)\n\n\ntest_data_generator = test_image_generator.flow_from_dataframe(\n    dataframe=test_data,\n    directory=path,\n    x_col ='path',\n    y_col ='label_str',\n    color_mode=\"rgb\",\n    target_size=(256, 256),\n    class_mode=\"binary\",\n    batch_size=32,\n    shuffle = False\n)\n","metadata":{"id":"kw_t6qAjN7il","execution":{"iopub.status.busy":"2024-05-02T22:05:43.176037Z","iopub.execute_input":"2024-05-02T22:05:43.176343Z","iopub.status.idle":"2024-05-02T22:07:14.867461Z","shell.execute_reply.started":"2024-05-02T22:05:43.176299Z","shell.execute_reply":"2024-05-02T22:07:14.866607Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# visualization","metadata":{}},{"cell_type":"code","source":"labels = train_data_generator.class_indices\nclass_names = list(labels.keys())\nprint('class names:',class_names)","metadata":{"id":"FGh9dwEqOQfa","execution":{"iopub.status.busy":"2024-05-02T22:19:48.074501Z","iopub.execute_input":"2024-05-02T22:19:48.075008Z","iopub.status.idle":"2024-05-02T22:19:48.080081Z","shell.execute_reply.started":"2024-05-02T22:19:48.074964Z","shell.execute_reply":"2024-05-02T22:19:48.079361Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nlabels = [\"Train\", \"Validation\", \"Test\"]\ncounts = [len(train_data), len(validation_data), len(test_data)]\n\nfig, ax = plt.subplots()\nax.pie(counts, labels=labels, autopct=\"%1.1f%%\")\nax.set_title(\"Distribution of Images\")\nplt.show()\n","metadata":{"id":"PxFHVQaFN8Ar","execution":{"iopub.status.busy":"2024-05-02T22:19:48.390023Z","iopub.execute_input":"2024-05-02T22:19:48.391003Z","iopub.status.idle":"2024-05-02T22:19:48.896860Z","shell.execute_reply.started":"2024-05-02T22:19:48.390953Z","shell.execute_reply":"2024-05-02T22:19:48.895140Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ntrain_size = len(train_data)\nvalidation_size = len(validation_data)\ntest_size = len(test_data)\n\nfig, ax = plt.subplots()\nx = ['Train', 'Validation', 'Test']\ny = [train_size, validation_size, test_size]\nax.bar(x, y)\nax.set_xlabel('Dataset')\nax.set_ylabel('Number of Images')\nax.set_title('Distribution of Images in Each Dataset')\n\nplt.show()","metadata":{"id":"JwJ-2NS4OANc","execution":{"iopub.status.busy":"2024-05-02T22:19:49.919109Z","iopub.execute_input":"2024-05-02T22:19:49.919599Z","iopub.status.idle":"2024-05-02T22:19:50.046455Z","shell.execute_reply.started":"2024-05-02T22:19:49.919559Z","shell.execute_reply":"2024-05-02T22:19:50.045536Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Convolutional Neural Networks (CNNs)\nCNNs have been widely used for image classification tasks. They excel at learning hierarchical features from raw pixel data. In the context of deepfake detection, CNNs can analyze patterns and features in images to distinguish between real and manipulated content.","metadata":{}},{"cell_type":"code","source":"model_cnn = Sequential()\n\nmodel_cnn.add(Conv2D(32,kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 3)))\nmodel_cnn.add(MaxPooling2D((2, 2)))\nmodel_cnn.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_cnn.add(MaxPooling2D((2, 2)))\nmodel_cnn.add(Conv2D(64, (3, 3), activation='relu'))\nmodel_cnn.add(MaxPooling2D((2, 2)))\nmodel_cnn.add(Dropout(0.2))\nmodel_cnn.add(Flatten())\nmodel_cnn.add(Dense(64, activation='relu'))\nmodel_cnn.add(Dropout(0.2))\nmodel_cnn.add(Dense(1, activation='sigmoid'))","metadata":{"id":"UGbWzCtEOEPj","execution":{"iopub.status.busy":"2024-05-02T22:49:36.726171Z","iopub.execute_input":"2024-05-02T22:49:36.726585Z","iopub.status.idle":"2024-05-02T22:49:36.818735Z","shell.execute_reply.started":"2024-05-02T22:49:36.726552Z","shell.execute_reply":"2024-05-02T22:49:36.817531Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_cnn.summary()","metadata":{"id":"I30hwESMOUvZ","execution":{"iopub.status.busy":"2024-05-02T22:36:35.529189Z","iopub.execute_input":"2024-05-02T22:36:35.529640Z","iopub.status.idle":"2024-05-02T22:36:35.548505Z","shell.execute_reply.started":"2024-05-02T22:36:35.529606Z","shell.execute_reply":"2024-05-02T22:36:35.547761Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_cnn.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"id":"MZu4rlZ9Oe38","execution":{"iopub.status.busy":"2024-05-02T22:36:37.033161Z","iopub.execute_input":"2024-05-02T22:36:37.033611Z","iopub.status.idle":"2024-05-02T22:36:37.042347Z","shell.execute_reply.started":"2024-05-02T22:36:37.033576Z","shell.execute_reply":"2024-05-02T22:36:37.041503Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model_cnn.fit(train_data_generator ,epochs = 10,validation_data= (validation_data_generator))","metadata":{"id":"j3V5oLm0OV5w","execution":{"iopub.status.busy":"2024-05-02T22:36:40.548097Z","iopub.execute_input":"2024-05-02T22:36:40.549020Z","iopub.status.idle":"2024-05-02T22:36:40.603076Z","shell.execute_reply.started":"2024-05-02T22:36:40.548980Z","shell.execute_reply":"2024-05-02T22:36:40.602002Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_accuracy = model_cnn.evaluate(test_data_generator)\nprint(f'Loss: {test_loss}, Accuracy: {test_accuracy}')","metadata":{"id":"i0XlEzJmOibl"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='validation loss')\nplt.legend()\nplt.show()\n\n\nplt.plot(history.history['accuracy'], label='train accuracy')\nplt.plot(history.history['val_accuracy'], label='validation accuracy')\nplt.legend()\nplt.show()\n","metadata":{"id":"mi29JnWJOrX8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import confusion_matrix\n\npredictions = model_cnn.predict(test_data_generator)\npredicted_labels = np.where(predictions > 0.5, 1, 0)\ntrue_labels = test_data_generator.classes\n\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\n\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=test_data_generator.class_indices,\n            yticklabels=test_data_generator.class_indices)\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"id":"g3pxTwCyOsj8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = list(test_data_generator.class_indices.keys())\nreport = classification_report(true_labels, predicted_labels, target_names=class_names)\nprint(\"Classification Report:\")\nprint(report)","metadata":{"id":"vcNK3tOjOtvB"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# XceptionNet\nXceptionNet is a deep learning architecture based on CNNs. It was designed to improve the efficiency of feature extraction by replacing standard convolutional layers with depthwise separable convolutions. XceptionNet has been successfully applied to various computer vision tasks, including deepfake detection.","metadata":{}},{"cell_type":"code","source":"base_model = Xception(weights='imagenet',include_top=False,input_shape=(256, 256, 3))\n","metadata":{"id":"4O77N1o9Otsy","execution":{"iopub.status.busy":"2024-05-02T22:26:35.997899Z","iopub.execute_input":"2024-05-02T22:26:35.998322Z","iopub.status.idle":"2024-05-02T22:26:37.589030Z","shell.execute_reply.started":"2024-05-02T22:26:35.998274Z","shell.execute_reply":"2024-05-02T22:26:37.588126Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for layer in base_model.layers:\n    layer.trainable = False\n\nXception_model = Sequential()\nXception_model.add(base_model)\nXception_model.add(Flatten())\nXception_model.add(BatchNormalization())\nXception_model.add(Dense(256, activation='relu'))\nXception_model.add(Dropout(0.5))\nXception_model.add(Dense(128, activation='relu'))\nXception_model.add(Dropout(0.5))\nXception_model.add(BatchNormalization())\nXception_model.add(Dense(1, activation='sigmoid'))\n\nXception_model.summary()","metadata":{"id":"U5r2yAKZPD6H","execution":{"iopub.status.busy":"2024-05-02T22:26:39.607864Z","iopub.execute_input":"2024-05-02T22:26:39.608270Z","iopub.status.idle":"2024-05-02T22:26:39.665575Z","shell.execute_reply.started":"2024-05-02T22:26:39.608237Z","shell.execute_reply":"2024-05-02T22:26:39.664482Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"Xception_model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])","metadata":{"id":"O8t5M7SkPGBW"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = Xception_model.fit(train_data_generator ,epochs = 10,validation_data= (validation_data_generator))\nprint(history.history)","metadata":{"id":"5J4Ok7NNPHYu"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_accuracy = Xception_model.evaluate(test_data_generator)\nprint(f'Loss: {test_loss}, Accuracy: {test_accuracy}')","metadata":{"id":"7wsR7FIEPIhW"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train loss')\nplt.plot(history.history['val_loss'], label='validation loss')\nplt.legend()\nplt.show()\n\nplt.plot(history.history['accuracy'], label='train accuracy')\nplt.plot(history.history['val_accuracy'], label='validation accuracy')\nplt.legend()\nplt.show()","metadata":{"id":"KqXGIa8hPJ_P"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\npredictions = Xception_model.predict(test_data_generator)\npredicted_labels = np.where(predictions > 0.5, 1, 0)\ntrue_labels = test_data_generator.classes\nconf_matrix = confusion_matrix(true_labels, predicted_labels)\nplt.figure(figsize=(8, 6))\nsns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n            xticklabels=test_data_generator.class_indices,\n            yticklabels=test_data_generator.class_indices)\nplt.xlabel('Predicted labels')\nplt.ylabel('True labels')\nplt.title('Confusion Matrix')\nplt.show()\n","metadata":{"id":"8vRSaB-dPKhK"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = list(test_data_generator.class_indices.keys())\nreport = classification_report(true_labels, predicted_labels, target_names=class_names)\n\nprint(\"Classification Report:\")\nprint(report)\n","metadata":{"id":"iJPAY1uwPNmo"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"id":"zjv4GzT_Pb_H"},"outputs":[],"execution_count":null}]}